---
title             : "Stability and Change in Adults' Literacy and Numeracy Skills: Evidence from two Large-scale Panel Studies"
shorttitle        : "Stability and Change in Adults' Literacy and Numeracy"

author: 
  - name          : "Clemens M. Lechner"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "B2, 1, 68159 Mannheim, Germany"
    email         : "clemens.lechner@gesis.org"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Funding acquisition
      - Supervision
      - Conceptualization
      - Data curation
      - Writing - Original Draft 
      - Writing - Review & Editing
      - Methodology 
  - name          : "Britta Gauly"
    affiliation   : "1"
    role:
      - Data curation
      - Methodology
      - Formal analysis
      - Writing - Review & Editing
  - name          : "Ai Miyamoto"
    affiliation   : "2"
    role: 
    - Writing - original draft
    - Writing - Review & Editing
  - name          : "Alexandra Wicht"
    affiliation   : "3"
    role:
      - Data curation
      - Formal analysis
      - Writing - Review & Editing
  
affiliation:
  - id            : "1"
    institution   : "GESIS - Leibniz Institute for the Social Sciences, Mannheim, Germany"
  - id            : "2"
    institution   : "University of Freiburg, Germany"
  - id            : "3"
    institution   : "University of Siegen, Germany"
  

authornote: |
  The authors would like to thank student assistants Marcel Kappes and Thomas Knopf for help during data curation and analysis.
  
abstract: |
 This study seeks to answer two questions about the development of literacy skills (reading competence) and numeracy skills (math competence) during adulthood: First, how stable are these skills in adulthood – and if they change, does change involve gains or losses? Second, how is change distributed in the population and in demographic subgroups? To answer these questions, we use data from two German large-scale surveys: The PIAAC longitudinal study (PIAAC-L; *N* = 1,775) and the National Educational Panel Study (NEPS; *N* = 3,087). Both surveys offer repeated, high-quality measures of adults’ literacy and numeracy spaced three (PIAAC-L) to six (NEPS) years apart. As complementary measures of change, we examine  rank-order stabilities ($r_{T1,T2}$) and mean-level stabilities ($\Delta_{T1,T2}$) of skills in the total population as well as in major socio-demographic subgroups defined by age, gender, and education. We used plausible value (PV) methodology to account for measurement error in skills. Results revealed that literacy and numeracy are hightly but not perfectly stable over time. Rank-order consistencies ranged from *r* = .83 for literacy and *r* = 0.81 for numeracy over three years in PIAAC_L to *r* = .65  for literacy and *r* = .75 for numeracy over six years in NEPS, with some variation across subgroups in NEPS but not PIAAC-L. Whereas mean-level change was negligible, there was considerable variation in change across individuals and subgroups. Few of these subgroup differences replicated across studies. We find some evidence for moderate skill gains during young adulthood (18–29 years) and losses in old age (55+ years), resembling age profiles from cross-sectional studies. Our findings suggest that adults' literacy and numeracy are not set in stone and can change even over relatively short time periods. They can serve as a benchmark against which to compare future longitudinal findings on stability and change in adult skills.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "literacy, numeracy, skills, intelligence, developoment, adulthood"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : yes
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
# Load required packages
getwd()
library(papaja)
library(tidyverse)
library(glue)
library(sjlabelled)
library(mice)
library(miceadds)
library(mitools)
library(srvyr)

# BibLateX Reference file
r_refs("r-references.bib")

# Load raw data and results
map(c(
  "math_neps.Rda", "reading_neps.Rda",
  "math_piaac.Rda", "reading_piaac.Rda",
  "./02_results/cors.Rda",
  "./02_results/deltas.Rda"
), load, .GlobalEnv)

```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction

In today’s knowledge-based and technology-rich societies, literacy (i.e., the ability to understand, use, and interpret written text) and numeracy (i.e., the ability to access, use, and interpret mathematical information)^[Some authors refer to literacy skills  as "reading competence" and to numeracy skills as "mathematical competence". There is no terminological consensus, and we use the term “skills”, "competencies", and "proficiencies" interchangeably throughout this article.] are quintessential skills for the welfare and well-being of individuals and societies at large. Literacy and numeracy skills have causal links to important individual (e.g., income, health, and social participation) and societal outcomes (e.g. economic growth; @hanushek2015; @hanushek2015a).
 
Demographic aging in most industrialized societies and rapid technological advances imply that the adult workforce will be increasingly required to update their skills throughout the life course, often well into the sixth decade of life. This trend toward lifelong learning in an aging workforce poses a number of important questions concerning the development of literacy and numeracy skills in adulthood. Because literacy and numeracy are key prerequisites to acquiring more specific knowledge and skills (e.g., reading a machine's manual or programming a computer) and not all individuals attain sufficient levels of literacy during schooling age [@durda2020], the key question is whether literacy and numeracy skills can still change during adulthood—or are  set like plaster after childhood and youth?  Moreover, does change in literacy and numeracy skills involve only losses - or do some adults experience proficiency gains? Moreover, how is skill change distributed in the adult population and in major subgroups such as age groups, genders, and different educational strata? 

These are not only interesting research questions in their own right, they are also of fundamental importance to policymakers and practitioners interested in promoting lifelong learning. If skills proved to be fully impervious to change during adulthood, investments in adults’ basic skills such as literacy and numeracy during adulthood might have a low return on investment, and childhood may be a more promising life stage for policies and interventions to focus on (e.g., @cunha2007). Alternatively, skills may change over time, but gains and losses may be unevenly distributed. In this case, identifying segments of the population that are more likely to experience age-related skill loss than others may aid the development of targeted policies and interventions. 

## Previous Evidence on Age Differences in Skills  
Given the policy relevance of these questions about skill development during adulthood, what answers can extant research provide us? Three key insights offered by current evidence are readily summarized [for comprehensive reviews, see @desjardins2012; @paccagnella2016]: (1) Lifelong plasticity of skills, (2) life stage dependency of change, and (3) individual and subgroup differences in change.

First, literacy and numeracy appear to continue to develop across adulthood. Both cross-sectional and the few available longitudinal studies suggest that these skills are not set like plaster after childhood but continue to change across the entire lifespan. Skill change during adulthood may involve both gains and losses. Second, gains and losses typically occur at different ages. As studies using data from international large-scale comparisons such as the Programme for the International Assessment of Adult Competencies (PIAAC) show, the cross-sectional age profile of literacy and numeracy follows an inverted u-shape: On average, literacy and numeracy skills continue to increase throughout the second decade of life, peak at around an age of 30 years, and gradually decline thereafter [e.g., @gabrielsen2014; @paccagnella2016; @podolskiy2014]. The resulting age differences in skills are substantial: On average across participating countries, older adults (aged 55–65 years) score about 30 scale points lower on the PIAAC literacy scale (the equivalent of 0.8 SD) than young adults aged 25–34 years [@paccagnella2016]. Third, beyond these average age trends, there are additional individual and group differences in  skill change. For example, using cross-sectional PIAAC 2012 data, @paccagnella2016 compared age-related age differences in literacy and numeracy skills among adults with different levels of educational attainment (i.e., primary, secondary, and territory or above) and found that those with the highest educational attainment experienced slightly larger skill loss during adulthood than those with lower educationsl attainment.

Although these prior studies have greatly advanced our knowledge about skill development in adulthood, they cannot conclusively answer the questions posed at the outset. This is because these studies are overwhelmingly based on large-scale cross-sectional surveys such as PIAAC and its predecessors (i.e., the International Adult Literacy Survey in 1994 and 1998 or the Adult Literacy and Life Skills Survey in 2003, 2006, and 2008); or on small-scale longitudinal studies based on selective samples such as the longitudinal study of adult learners (LSAL) that focuses on  high-school dropouts in the US [@reder2009].  Cross-sectional studies into the age-related changes in literacy and numeracy skills are limited in that they are unable to disentangle age effects from cohort effects. That is, they are unable to ascertain whether the putative age differences are due to age-related changes or stem from preexisting differences in skills during childhood. Small-scale longitudinal studies based on selective samples, on the other hand, are limited in that their findings may not generalize to the population as a whole. Moreover, by their very nature, these studies cover some subgroups (e.g., high-school dropouts) in a certain life stage (e.g., young adulthood)–but not others subgroups (e.g., the highly educated) and life stages (e.g., old age) that may be of equal interest to policymakers and practitioners. Also, compared to literacy, the life-span development numeracy has received much less attention by prior research, despite arguments in the literature that numeracy skills are gaining in importance on today’s labor markets [e.g., @gal2020; @gauly2020].

In order to overcome the limitations of cross-sectional and small-scale longitudinal designs, repeated measures of literacy and numeracy skills are needed. Such data have long been in short supply. Until very recently, there were simply no data sources available internationally that combined  the following desirable features that would allow for complete and robust answers to questions surrounding age-related changes in skills during adulthood: A large and non-selective sample; objective, and high-quality skill assessments; and a repeated measures design.

## The Present Research 
In the present study, we leverage the unique analytical potential of two recent German large-scale assessment surveys that do meet the above criteria: PIAAC-longitudinal (PIAAC-L), a follow-up to the 2012 Programme for the International Assessment of Adult Competencies (PIAAC) study in Germany; and Starting Cohort 6 from the National Educational Panel Study (NEPS). Both surveys offer repeated, high-quality––and largely comparable––measures of adults' literacy and numeracy spaced three years (PIAAC-L) to six years (NEPS) apart. Combining these data offers us unprecedented opportunities to analyze age-related changes in literacy and numeracy skills during adulthood, allowing us to present what appear to be the most comprehensive descriptive analyses of age-related changes of literacy and numeracy skills during adulthood to date.

With these data, we seek to answer two guiding questions about the stability and change of adults' literacy and numeracy skills. First, to what extent do these skills change across the three- to six-year periods covered by PIAAC-L and NEPS? Second, does the extent of age-related change differ across major socio-demographic groups? 

We approach these questions from two perspectives on age-related change enabled by the repeated-measures designs: (1) relative change as captured by the correlation between literacy or numeracy skills measured at two time points, $r_{T1,T2}$; and (2) absolute change as capture by the change score, $\Delta_{T1,T2}$ (for details, see Method). We present descriptive analyses of change both for the total samples as well as in major socio-demographic subgroups defined by age, gender, and educational attainment. These subgroup analyses allow us to detect potential socio-demographic gradients in literacy and numeracy development. Of particular interest to our study is the question whether the age differences in skills and subgroup differences therein that we obtain through our repeated-measures designs parallel, or differ from, estimates of age differences obtained in cross-sectional designs [e.g., those reported by @paccagnella2016]?

# Methods
For full transparency, the completely reproducible R code for this study is available from the first author's github repository at [blinded for review]. The PIAAC-L and NEPS data upon which this code builds are are available upon registration from  https://www.gesis.org/en/piaac/rdc/data/piaac-longitudinal and https://www.neps-data.de/, respectively.

## Data and Samples

### PIAAC/PIAAC-L
 Our first data source is the German PIAAC/PIAAC-L study [version 3-0-0; @gesis2017]. PIAAC was conducted in 2012 and provides internationally comparable data on the skills of the working-age population (16–65 years) residing in private households in large number of (mainly OECD) countries (@oecd2013a). In Germany, a registry-based sampling design was implemented, in which respondents were randomly sampled from local population registers in randomly selected German municipalities. A total of 5,465 interviews in respondents’ homes were achieved. At the end of the PIAAC interview, all German PIAAC respondents were asked whether they were willing to be re-contacted for a follow-up study (i.e., PIAAC-L) in the future. A total of 3,758 (or 69%) of the original 5,465 PIAAC 2012 respondents consented to being re-interviewed and could be successfully contacted for the first follow-up wave in 2014. 
Literacy and numeracy skills were assessed in PIAAC in 2012 (henceforth "T1") and again three years later in PIAAC-L wave 2 in 2015 (henceforth "T2"). Our longitudinal sample contains the `r nrow(reading_piaac) / max(reading_piaac$.imp)` adults aged 18-65 at T1 for who took the test at both measurement occasions. For the longitudinal analyses, we multiplied the total sample weight of PIAAC 2012 with a factor that accounts for non-response in PIAAC-L 2015. For more details on the samples, procedures and weighting, see the technical reports to PIAC 2012 Germany and PIAAC-L [@zabal2014; @zabal2017].  Table 1 (right column) shows the (unweighted) socio-demographic characteristics of the PIAAC-L sample at T1.


### NEPS
Our second data source is Starting Cohort 6 (Adults) of NEPS [version 11-0-0; @artelt2020]. NEPS is an ongoing large-scale, multi-cohort, longitudinal survey on educational trajectories in Germany [for a detailed description including sampling procedures, see, @blossfeld2011]. Starting Cohort 6 comprised a sample of initially 11,649 adults aged 22–65 years who were interviewed in up to nine annual waves so far. 
Literacy and numeracy skills were assessed twice, first in 2010/2011 (henceforth "T1") and again six years later in 2016/2017 ("T2"). Our longtitudinal sample comprises `r nrow(reading_neps) / max(reading_neps$.imp)` respondents who took the literacy test at both occasions and `r nrow(math_neps) / max(math_neps$.imp)` respondents for numeracy. We used longitudinal weights (NEPS variable *w_t456789_std*) for individuals who continuously participated until T2 (wave 9), which are computed by means of the longitudinal weight of the previous wave, the probability of being part of the used sample, and the likelihood of participating at T2 [for details on the weighting procedure, see @hammon2018]. Table 1 (right column) shows the (unweighted) socio-demographic characteristics of the NEPS sample at T1.

## Measures of Literacy and Numeracy
PIAAC/PIAAC-L and NEPS assessed literacy and numeracy in comparable ways, despite some differences in the assessment approach [for details, see @durda2020]. In both surveys, the tests were low-stakes assessment. Thus, the test scores are likely to reflect typical, rather than maximum performance. However, the procedures in both surveys were designed to ensure that respondents took the test situation seriously and to ensure objectivity. 

### PIAAC assessment approach
In PIAAC and PIAAC-L, literacy and numeracy skills were assessed through comprehensive, extensively validated (including cross-nationally) tests. Test tasks were devised by an international commission of eminent scholars. The tasks were designed to reflect tasks relevant to everyday life , which respondents were typically highly motivated to solve. Respondents either took a computer-based assessment (86.2% in our analytical sample in 2012; 88.1% in 2015) or, if they had no experience using a computer , on a paper-pencil version (13.8% in 2012 and 11.8% in 2015). Depending on whether respondents took the computer-based assessment or paper-based assessment, they received different testlets that comprised different subsets of the test tasks. The computer-based assessment was a multistage adaptive testing design that consisted of different literacy and numeracy testlets (each comprising 20 tasks) to which respondents were assigned. The paper-based assessment comprised 20 fixed items for literacy and for numeracy. Interviewers were thoroughly trained for the assessment, they were present while respondents took the tests, and monitored the process. There was no time limit (i.e., tests were not speeded). On average, respondents took about 50 minutes to complete the assessment. For further information on the PIAAC assessment frameworks, see OECD (2012).
The PIAAC/PIAAC-L data distribution provides ten plausible values (PV) ) per respondent and per skill domain and measurement occasion based on item response theory models (IRT). We ran each of our analyses (described below) separately on each of the 10 plausible values and aggregated the results while correcting standard errors (for further details on using plausible values, see Von Davier, Gonzalez, & Mislevy, 2009; Wu, 2005). By using plausible values, covariance-based statistics are corrected for measurement error.

### NEPS assessment approach. 
In NEPS, literacy (or, in NEPS terminology, “reading competence”) and numeracy (“mathematical competence”) were assessed through a paper-pencil-based assessment at T1 and a multistage adaptive computer-based assessment at T2. Much akin to PIAAC, the tests were designed to measure skills needed in everyday life. Different to PIAAC, the tests were speeded. The T1 literacy test comprised 32 items, which respondents were asked to complete in 28 minutes. The T1 numeracy test comprised 22 items for which another 28 minutes were available. Respondents were randomly assigned different booklets, and not all respondents took both tests; however, all respondents received all items from a given booklet. At T2, by a multistage design was employed , with respondents receiving one of two booklets of varying difficulty levels depending on their previous performance at T1 (literacy) or their performance in an initial block of tasks at T2 (numeracy). The T2 literacy booklets comprised 27 or 26 items and the numeracy booklet comprised 21 items.  For further information on the NEPS assessment framework, see REFERENCE(YEAR). 


## Material

## Procedure

## Data analysis


We used `r cite_r("r-references.bib")` for all our analyses.


# Results
```{r load_results}
# Seed for random number generation
library(tidyverse)
library(mitools)
library(extrafont)
load("math_neps.Rda")
load("reading_neps.Rda")
load("math_piaac.Rda")
load("reading_piaac.Rda")

change_neps <- full_join(
  select(reading_neps, .imp, id = ID_t, t1_read = t1_pv, t2_read = t2_pv, weight),
  select(math_neps, .imp, id = ID_t, t1_math = t1_pv, t2_math = t2_pv),
  by = c("id", ".imp")
) %>%
  mutate(diff_read = t2_read - t1_read,
         diff_math = t2_math - t1_math) %>%
  select(.imp, diff_read, diff_math, t1_read, t2_read, weight) %>%
split(.$.imp) %>% 
 imputationList()

change_neps <- with(change_neps, lm(scale(diff_read) ~ scale(diff_math),
                   weights = weight
    )
  ) %>%
    MIcombine() %>%
    summary()

change_piaac <- full_join(
  select(reading_piaac, .imp, id = seqid, t1_read = t1_pv, t2_read = t2_pv, weight),
  select(math_piaac, .imp, id = seqid, t1_math = t1_pv, t2_math = t2_pv),
  by = c(".imp", "id")
) %>%
  mutate(diff_read = t2_read - t1_read,
         diff_math = t2_math - t1_math) %>%
  select(.imp, diff_read, diff_math, t1_read, t2_read, weight) %>%
split(.$.imp) %>% 
 imputationList()

change_piaac <- with(change_piaac, lm(scale(diff_read) ~ scale(diff_math),
                   weights = weight
    )
  ) %>%
    MIcombine() %>%
    summary()

change_piaac

```

# Discussion

# Footnotes


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
